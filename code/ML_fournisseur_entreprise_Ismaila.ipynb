{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4bd2a1ea",
   "metadata": {},
   "source": [
    "# ISMAILA LE GOAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f27cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33eb06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data \n",
    "df=pd.read_csv(\"../code/achat_prod_fournisseur_stock.csv\") #upload from code file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40349ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73185560",
   "metadata": {},
   "outputs": [],
   "source": [
    "# √âtape 1 : Correction des anomalies\n",
    "# Corriger les dates invalides\n",
    "df['date_achat'] = pd.to_datetime(df['date_achat'], errors='coerce')\n",
    "\n",
    "# √âtape 2 : V√©rification et correction des types\n",
    "df['fiabilit√©'] = pd.to_numeric(df['fiabilit√©'], errors='coerce')\n",
    "\n",
    "# √âtape 3 : Cr√©ation de nouvelles colonnes\n",
    "df['√©cart_d√©lai'] = df['d√©lai_livraison_jours'] - df['d√©lai_moyen_jours']\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1584c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistiques descriptives pour les colonnes num√©riques\n",
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "\n",
    "# Select numeric columns and calculate descriptive statistics\n",
    "numeric_columns = df.select_dtypes(include=['number']).columns\n",
    "desc_stats_updated = df[numeric_columns].describe()\n",
    "\n",
    "# Detect outliers using the Interquartile Range (IQR) method\n",
    "extremes = {}\n",
    "for col in numeric_columns:\n",
    "    Q1 = df[col].quantile(0.25)\n",
    "    Q3 = df[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    outliers = df[(df[col] < lower_bound) | (df[col] > upper_bound)]\n",
    "    extremes[col] = {\n",
    "        'nb_outliers': outliers.shape[0],\n",
    "        'lower_bound': lower_bound,\n",
    "        'upper_bound': upper_bound\n",
    "    }\n",
    "\n",
    "# Create a DataFrame for the outliers\n",
    "extremes_df = pd.DataFrame(extremes).T.sort_values(by='nb_outliers', ascending=False)\n",
    "\n",
    "# Display the DataFrame (replace ace_tools if unavailable)\n",
    "print(extremes_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "242a3606",
   "metadata": {},
   "source": [
    "les r√©sultats de l'analyse des valeurs extr√™mes dans le fichier :\n",
    "\n",
    "üö© Variables avec le plus d'outliers :\n",
    "quantit√© : 794 valeurs hors de l‚Äôintervalle [‚àí87.5, 212.5]\n",
    "\n",
    "montant_total : 709 valeurs extr√™mes\n",
    "\n",
    "d√©lai_moyen_jours : 262 cas hors norme\n",
    "\n",
    "prix_unitaire et d√©lai_livraison_jours : aucune valeur extr√™me d√©tect√©e selon l'IQR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121bd87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# S√©lection des 3 variables avec le plus d'outliers\n",
    "top_outlier_cols = extremes_df.head(3).index.tolist()\n",
    "\n",
    "# Cr√©ation de boxplots pour visualiser les valeurs extr√™mes\n",
    "plt.figure(figsize=(12, 6))\n",
    "for i, col in enumerate(top_outlier_cols, 1):\n",
    "    plt.subplot(1, 3, i)\n",
    "    sns.boxplot(y=df[col])\n",
    "    plt.title(f\"Boxplot - {col}\")\n",
    "    plt.tight_layout()\n",
    "\n",
    "plt.suptitle(\"Visualisation des valeurs extr√™mes\", y=1.05)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d07be6",
   "metadata": {},
   "source": [
    "les visualisations des valeurs extr√™mes pour les variables :\n",
    "\n",
    "quantit√©\n",
    "\n",
    "montant_total\n",
    "\n",
    "d√©lai_moyen_jours\n",
    "\n",
    "Ces boxplots montrent clairement les observations situ√©es bien au-del√† des bornes normales (au-dessus des moustaches)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede21747",
   "metadata": {},
   "outputs": [],
   "source": [
    "# √âtape 5 : V√©rification des valeurs manquantes apr√®s conversion\n",
    "missing_values = df.isnull().sum()\n",
    "\n",
    "df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4970e668",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Bo√Ætes √† moustaches pour visualiser les distributions et valeurs extr√™mes\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(data=df[['quantit√©', 'd√©lai_livraison_jours', 'niveau_stock', '√©cart_d√©lai']])\n",
    "plt.title('Distribution des variables quantitatives avec valeurs extr√™mes')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "desc_stats, missing_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ab852e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.metrics import mean_squared_error, classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Variables pour les diff√©rentes pr√©dictions\n",
    "features_common = ['mois', 'ann√©e', 'jour_semaine', 'prix_unitaire', 'fiabilit√©', 'stock_minimum', 'niveau_stock']\n",
    "categorical_features = ['cat√©gorie', 'marque', 'pays', 'entrepot']\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03acec38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mod√®le 1 : Pr√©diction de la quantit√© achet√©e\n",
    "X_quantit√© = df[features_common + categorical_features]\n",
    "y_quantit√© = df['quantit√©']\n",
    "\n",
    "# Pr√©paration pipeline avec encodage\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "], remainder='passthrough')\n",
    "\n",
    "# Split des donn√©es\n",
    "X_train_q, X_test_q, y_train_q, y_test_q = train_test_split(X_quantit√©, y_quantit√©, test_size=0.2, random_state=42)\n",
    "\n",
    "# Pipeline de r√©gression\n",
    "pipeline_quantit√© = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', RandomForestRegressor(n_estimators=100, random_state=42))\n",
    "])\n",
    "\n",
    "pipeline_quantit√©.fit(X_train_q, y_train_q)\n",
    "y_pred_q = pipeline_quantit√©.predict(X_test_q)\n",
    "rmse_q = mean_squared_error(y_test_q, y_pred_q, squared=False)\n",
    "\n",
    "rmse_q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a768bccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Suppression de la ligne avec date invalide\n",
    "df_clean = df.dropna(subset=['date_achat'])\n",
    "\n",
    "# Encodage des variables cat√©gorielles pertinentes\n",
    "df_encoded = pd.get_dummies(df_clean, columns=['cat√©gorie', 'marque', 'pays', 'entrepot'], drop_first=True)\n",
    "\n",
    "# S√©lection des features pour pr√©dire la quantit√©\n",
    "features_quantit√© = ['prix_unitaire', 'd√©lai_livraison_jours', 'fiabilit√©', 'niveau_stock', 'stock_minimum', '√©cart_d√©lai']\n",
    "features_quantit√© += [col for col in df_encoded.columns if col.startswith(('cat√©gorie_', 'marque_', 'pays_', 'entrepot_'))]\n",
    "\n",
    "X = df_encoded[features_quantit√©]\n",
    "y = df_encoded['quantit√©']\n",
    "\n",
    "# S√©paration des donn√©es\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# R√©gression lin√©aire\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# √âvaluation\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Visualisation : pr√©dictions vs r√©els\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(x=y_test, y=y_pred, alpha=0.4)\n",
    "plt.xlabel(\"Quantit√© r√©elle\")\n",
    "plt.ylabel(\"Quantit√© pr√©dite\")\n",
    "plt.title(\"Pr√©diction de la quantit√© achet√©e - R√©gression lin√©aire\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "mse, r2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd3fa899",
   "metadata": {},
   "source": [
    "La mod√©lisation de la quantit√© achet√©e √† l'aide d'une r√©gression lin√©aire donne les r√©sultats suivants :\n",
    "\n",
    "üìà R√©sultats de la r√©gression lin√©aire\n",
    "MSE (Erreur quadratique moyenne) : 9067.01\n",
    "\n",
    "R¬≤ (coefficient de d√©termination) : -0.0016\n",
    "\n",
    "‚ùå Conclusion : Le mod√®le n'explique pratiquement rien de la variance (R¬≤ ‚âà 0), ce qui signifie que la r√©gression lin√©aire n'est pas adapt√©e ici. Les pr√©dictions sont tr√®s proches de la moyenne, quelle que soit l'entr√©e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a4a47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Entra√Ænement du mod√®le Random Forest\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "rf_pred = rf_model.predict(X_test)\n",
    "\n",
    "# √âvaluation\n",
    "rf_mse = mean_squared_error(y_test, rf_pred)\n",
    "rf_r2 = r2_score(y_test, rf_pred)\n",
    "\n",
    "# Visualisation des importances des variables\n",
    "importances = pd.Series(rf_model.feature_importances_, index=X.columns)\n",
    "importances_sorted = importances.sort_values(ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=importances_sorted.values[:15], y=importances_sorted.index[:15])\n",
    "plt.title(\"Top 15 des variables les plus importantes - Random Forest\")\n",
    "plt.xlabel(\"Importance\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "rf_mse, rf_r2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "552cd2ae",
   "metadata": {},
   "source": [
    "Le mod√®le Random Forest donne des r√©sultats l√©g√®rement meilleurs mais encore insuffisants :\n",
    "\n",
    "üå≤ R√©sultats du mod√®le Random Forest\n",
    "MSE : 9831.67 (un peu plus √©lev√© que la r√©gression lin√©aire)\n",
    "\n",
    "R¬≤ : -0.086 ‚Üí toujours tr√®s mauvais (le mod√®le est pire que la moyenne simple).\n",
    "\n",
    "üìä Variables les plus importantes :\n",
    "Le graphique montre les 15 variables ayant le plus de poids dans la pr√©diction. Parmi les plus influentes, on retrouve g√©n√©ralement :\n",
    "\n",
    "prix_unitaire\n",
    "\n",
    "niveau_stock\n",
    "\n",
    "stock_minimum\n",
    "\n",
    "Certaines cat√©gories ou marques sp√©cifiques\n",
    "\n",
    "‚ùìInterpr√©tation\n",
    "La variable cible \"quantit√© achet√©e\" semble difficilement pr√©visible √† partir des donn√©es disponibles. Il est possible que :\n",
    "\n",
    "D'autres facteurs importants soient absents (budgets, promotions, saisonnalit√© fine, etc.).\n",
    "\n",
    "Ou que la variable soit sujette √† une grande variabilit√© al√©atoire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f543c1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mod√®le 2 : Pr√©diction du d√©lai de livraison\n",
    "X_d√©lai = df[features_common + categorical_features]\n",
    "y_d√©lai = df['d√©lai_livraison_jours']\n",
    "\n",
    "# Split des donn√©es\n",
    "X_train_d, X_test_d, y_train_d, y_test_d = train_test_split(X_d√©lai, y_d√©lai, test_size=0.2, random_state=42)\n",
    "\n",
    "# Pipeline de r√©gression\n",
    "pipeline_d√©lai = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', RandomForestRegressor(n_estimators=100, random_state=42))\n",
    "])\n",
    "\n",
    "pipeline_d√©lai.fit(X_train_d, y_train_d)\n",
    "y_pred_d = pipeline_d√©lai.predict(X_test_d)\n",
    "rmse_d = mean_squared_error(y_test_d, y_pred_d, squared=False)\n",
    "\n",
    "rmse_d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8197769f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppression des colonnes non num√©riques non encod√©es\n",
    "cols_to_drop = ['d√©lai_livraison_jours', 'quantit√©', 'montant_total', 'date_achat', 'id_achat',\n",
    "                'id_produit', 'id_fournisseur', 'nom_fournisseur', 'ville']\n",
    "X_delay_cleaned = df_encoded.drop(columns=cols_to_drop)\n",
    "y_delay = df_encoded['d√©lai_livraison_jours']\n",
    "\n",
    "# S√©paration train/test\n",
    "X_train_d, X_test_d, y_train_d, y_test_d = train_test_split(X_delay_cleaned, y_delay, test_size=0.2, random_state=42)\n",
    "\n",
    "# Entra√Ænement Random Forest\n",
    "rf_delay_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_delay_model.fit(X_train_d, y_train_d)\n",
    "y_pred_delay = rf_delay_model.predict(X_test_d)\n",
    "\n",
    "# √âvaluation\n",
    "mse_delay = mean_squared_error(y_test_d, y_pred_delay)\n",
    "r2_delay = r2_score(y_test_d, y_pred_delay)\n",
    "\n",
    "# Visualisation : Pr√©diction vs R√©el\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(x=y_test_d, y=y_pred_delay, alpha=0.4)\n",
    "plt.xlabel(\"D√©lai r√©el (jours)\")\n",
    "plt.ylabel(\"D√©lai pr√©dit (jours)\")\n",
    "plt.title(\"Pr√©diction du d√©lai de livraison fournisseur\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "mse_delay, r2_delay\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7292a9f",
   "metadata": {},
   "source": [
    "La pr√©diction du d√©lai de livraison fournisseur avec le mod√®le Random Forest est tr√®s performante :\n",
    "\n",
    "‚úÖ R√©sultats du mod√®le\n",
    "MSE : 0.0041 ‚Üí tr√®s faible erreur moyenne.\n",
    "\n",
    "R¬≤ : 0.9997 ‚Üí le mod√®le explique quasiment toute la variance des d√©lais.\n",
    "\n",
    "üìä Interpr√©tation\n",
    "Les donn√©es disponibles contiennent des variables tr√®s corr√©l√©es au d√©lai de livraison (probablement d√©lai_moyen_jours, fiabilit√©, ou certaines cat√©gories/fournisseurs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6f7d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mod√®le 3 : Classification des fournisseurs selon leur pays\n",
    "# Pour cela on utilise les caract√©ristiques li√©es au fournisseur\n",
    "\n",
    "X_pays = df[['fiabilit√©', 'd√©lai_moyen_jours', 'stock_minimum', 'niveau_stock', 'entrepot', 'ville']]\n",
    "y_pays = df['pays']\n",
    "\n",
    "# Encodage des variables cat√©gorielles\n",
    "categorical_pays_features = ['entrepot', 'ville']\n",
    "preprocessor_pays = ColumnTransformer(transformers=[\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_pays_features)\n",
    "], remainder='passthrough')\n",
    "\n",
    "# Split\n",
    "X_train_p, X_test_p, y_train_p, y_test_p = train_test_split(X_pays, y_pays, test_size=0.2, random_state=42)\n",
    "\n",
    "# Pipeline\n",
    "pipeline_pays = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor_pays),\n",
    "    ('classifier', RandomForestClassifier(n_estimators=100, random_state=42))\n",
    "])\n",
    "\n",
    "pipeline_pays.fit(X_train_p, y_train_p)\n",
    "y_pred_p = pipeline_pays.predict(X_test_p)\n",
    "report_pays = classification_report(y_test_p, y_pred_p, output_dict=True)\n",
    "\n",
    "# Conversion du rapport en DataFrame\n",
    "report_pays_df = pd.DataFrame(report_pays).transpose()\n",
    "\n",
    "# Affichage du DataFrame\n",
    "print(\"Rapport Classification Fournisseurs par Pays\")\n",
    "print(report_pays_df)\n",
    "\n",
    "# Matrice de confusion\n",
    "cm = confusion_matrix(y_test_c, y_pred_c, labels=clf.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=clf.classes_)\n",
    "disp.plot(xticks_rotation=45, cmap='Blues')\n",
    "plt.title(\"Matrice de confusion - Classification du pays du fournisseur\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20865ab6",
   "metadata": {},
   "source": [
    "La classification du pays du fournisseur donne d‚Äôexcellents r√©sultats pour les pays les plus repr√©sent√©s :\n",
    "\n",
    "üéØ Performances (extraits)\n",
    "Allemagne : Pr√©cision 93.7%, Recall 97.4%, F1-score 95.5%\n",
    "\n",
    "Finlande : Pr√©cision 97.5%, Recall 99.8%, F1-score 98.6%\n",
    "\n",
    "Les petits pays (comme Espagne, Danemark) ont des performances plus faibles √† cause d‚Äôun nombre d‚Äôexemples limit√©.\n",
    "\n",
    "üîé Le mod√®le est tr√®s fiable pour les pays majoritaires, mais pourrait √™tre am√©lior√© pour les pays minoritaires via du r√©√©quilibrage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17a11ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mod√®le 4 : Analyse des niveaux de stock par entrep√¥t\n",
    "# On va pr√©dire le niveau de stock selon entrep√¥t (mod√®le de r√©gression)\n",
    "\n",
    "X_stock = df[['mois', 'ann√©e', 'jour_semaine', 'prix_unitaire', 'quantit√©', 'fiabilit√©', 'stock_minimum', 'entrepot']]\n",
    "y_stock = df['niveau_stock']\n",
    "\n",
    "categorical_stock_features = ['entrepot']\n",
    "preprocessor_stock = ColumnTransformer(transformers=[\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_stock_features)\n",
    "], remainder='passthrough')\n",
    "\n",
    "# Split\n",
    "X_train_s, X_test_s, y_train_s, y_test_s = train_test_split(X_stock, y_stock, test_size=0.2, random_state=42)\n",
    "\n",
    "# Pipeline\n",
    "pipeline_stock = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor_stock),\n",
    "    ('regressor', RandomForestRegressor(n_estimators=100, random_state=42))\n",
    "])\n",
    "\n",
    "pipeline_stock.fit(X_train_s, y_train_s)\n",
    "y_pred_s = pipeline_stock.predict(X_test_s)\n",
    "rmse_s = mean_squared_error(y_test_s, y_pred_s, squared=False)\n",
    "\n",
    "rmse_s\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f603f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bo√Æte √† moustaches : distribution du niveau de stock par entrep√¥t\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(data=df_clean, x='entrepot', y='niveau_stock')\n",
    "plt.title(\"Distribution des niveaux de stock par entrep√¥t\")\n",
    "plt.xlabel(\"Entrep√¥t\")\n",
    "plt.ylabel(\"Niveau de stock\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Moyenne du stock par entrep√¥t\n",
    "stock_by_entrepot = df_clean.groupby('entrepot')['niveau_stock'].agg(['mean', 'median', 'std', 'count']).sort_values('mean', ascending=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "866f20c7",
   "metadata": {},
   "source": [
    " l'analyse des niveaux de stock par entrep√¥t :\n",
    "\n",
    "üìä Visualisation\n",
    "Les entrep√¥ts Paris, Lyon, et Marseille montrent des distributions similaires mais avec quelques diff√©rences de m√©diane et de dispersion.\n",
    "\n",
    "Des valeurs extr√™mes sont visibles dans chaque entrep√¥t.\n",
    "\n",
    "üìà Statistiques principales\n",
    "Paris a le niveau moyen de stock le plus √©lev√© (~150.6).\n",
    "\n",
    "Lyon est proche (~147.6), mais avec une plus grande dispersion.\n",
    "\n",
    "Marseille a le niveau moyen le plus bas (~139.0) et la plus petite m√©diane."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "887a32da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Extraire les importances des features\n",
    "feature_names = pipeline_stock.named_steps['preprocessor'].get_feature_names_out().tolist() + [\n",
    "    f for f in X_stock.columns if f not in categorical_stock_features\n",
    "]\n",
    "importances = pipeline_stock.named_steps['regressor'].feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Tracer l'importance des variables\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.title(\"Importance des variables pour la pr√©diction du niveau de stock\")\n",
    "plt.bar(range(len(importances)), importances[indices], align='center')\n",
    "plt.xticks(range(len(importances)), np.array(feature_names)[indices], rotation=90)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8dad26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Moyennes des niveaux de stock par entrep√¥t\n",
    "stock_features = df_clean.groupby('entrepot')[['niveau_stock']].mean()\n",
    "\n",
    "# Standardisation\n",
    "scaler = StandardScaler()\n",
    "stock_scaled = scaler.fit_transform(stock_features)\n",
    "\n",
    "# Clustering avec KMeans (choix de 3 clusters pour tester)\n",
    "kmeans = KMeans(n_clusters=3, random_state=42, n_init=10)\n",
    "stock_features['cluster'] = kmeans.fit_predict(stock_scaled)\n",
    "\n",
    "# Visualisation\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.barplot(x=stock_features.index, y=stock_features['niveau_stock'], hue=stock_features['cluster'], dodge=False)\n",
    "plt.title(\"Segmentation des entrep√¥ts par niveau moyen de stock\")\n",
    "plt.ylabel(\"Niveau moyen de stock\")\n",
    "plt.xlabel(\"Entrep√¥t\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d2483e",
   "metadata": {},
   "source": [
    " la segmentation des entrep√¥ts selon leur niveau moyen de stock √† l‚Äôaide de KMeans :\n",
    "\n",
    "üß† Clustering\n",
    "Les entrep√¥ts ont √©t√© r√©partis en 3 clusters distincts.\n",
    "\n",
    "Cela permet d‚Äôidentifier des sites avec un stock √©lev√©, moyen ou faible.\n",
    "\n",
    "On peut utiliser cette segmentation pour adapter les politiques de r√©assort, de capacit√©, ou pour √©quilibrer les flux logistiques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b3e324",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ace_tools "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035c669c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, accuracy_score, top_k_accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# Nettoyage de la date\n",
    "df['date_achat'] = pd.to_datetime(df['date_achat'], errors='coerce')\n",
    "df = df.dropna(subset=['date_achat'])  # supprimer les lignes avec dates invalides\n",
    "\n",
    "# Feature engineering\n",
    "df['√©cart_d√©lai'] = df['d√©lai_livraison_jours'] - df['d√©lai_moyen_jours']\n",
    "\n",
    "# Suppression des colonnes inutiles\n",
    "drop_cols = ['id_achat', 'date_achat', 'id_produit', 'nom_fournisseur', 'ville']\n",
    "df_features = df.drop(columns=drop_cols)\n",
    "\n",
    "# Encodage de la variable cible\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(df['id_produit'])\n",
    "\n",
    "# Encodage des variables cat√©gorielles restantes\n",
    "X = pd.get_dummies(df_features, drop_first=True)\n",
    "\n",
    "# S√©paration des donn√©es\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Entra√Ænement du mod√®le\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Pr√©diction\n",
    "y_pred = clf.predict(X_test)\n",
    "y_proba = clf.predict_proba(X_test)\n",
    "\n",
    "\n",
    "# Provide all known classes to the `labels` parameter\n",
    "all_classes = clf.classes_  # Extract all classes from the trained classifier\n",
    "top_3_accuracy = top_k_accuracy_score(y_test, y_proba, k=3, labels=all_classes)\n",
    "\n",
    "# Evaluation\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred, output_dict=True)\n",
    "report_df = pd.DataFrame(report).transpose()\n",
    "\n",
    "# Display the classification report\n",
    "print(\"Rapport de classification - Produits\")\n",
    "print(report_df)\n",
    "\n",
    "# Optionally, save the report to a CSV file for further analysis\n",
    "report_df.to_csv(\"classification_report_produits.csv\", index=True)\n",
    "\n",
    "# Return accuracy and top-3 accuracy\n",
    "accuracy, top_3_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b319423",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96de84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilisation de LightGBM pour classifier les produits parmi le top 50\n",
    "import lightgbm as lgb\n",
    "\n",
    "# Cr√©ation du dataset LightGBM\n",
    "lgb_train = lgb.Dataset(X_train_top, label=y_train_top)\n",
    "lgb_eval = lgb.Dataset(X_test_top, label=y_test_top, reference=lgb_train)\n",
    "\n",
    "# Param√®tres de base pour multiclass\n",
    "params = {\n",
    "    'objective': 'multiclass',\n",
    "    'num_class': len(np.unique(y_train_top)),\n",
    "    'metric': 'multi_logloss',\n",
    "    'verbosity': -1,\n",
    "    'seed': 42\n",
    "}\n",
    "\n",
    "# Entra√Ænement\n",
    "lgb_model = lgb.train(params, lgb_train, valid_sets=[lgb_eval], num_boost_round=100, early_stopping_rounds=10, verbose_eval=False)\n",
    "\n",
    "# Pr√©dictions\n",
    "y_proba_lgb = lgb_model.predict(X_test_top)\n",
    "y_pred_lgb = np.argmax(y_proba_lgb, axis=1)\n",
    "\n",
    "# √âvaluation\n",
    "accuracy_lgb = accuracy_score(y_test_top, y_pred_lgb)\n",
    "top3_accuracy_lgb = top_k_accuracy_score(y_test_top, y_proba_lgb, k=3, labels=np.arange(y_proba_lgb.shape[1]))\n",
    "\n",
    "accuracy_lgb, top3_accuracy_lgb\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
